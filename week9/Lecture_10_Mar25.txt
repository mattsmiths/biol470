1
00:00:09,450 --> 00:00:14,099
[Auto-generated transcript. Edits may have been applied for clarity.]
All right? Yeah. Welcome back. Um, yeah.

2
00:00:14,100 --> 00:00:17,790
Hopefully everyone had a relaxing and restorative, uh, spring break.

3
00:00:18,450 --> 00:00:22,889
Um, I know. Yeah, I got a little bit more sleep. Um, yeah.

4
00:00:22,890 --> 00:00:27,209
So I'm feeling good. Um, yeah, I think last class.

5
00:00:27,210 --> 00:00:32,370
Right. We had that annoying beeping sound happening outside. Now fix all good things.

6
00:00:33,030 --> 00:00:37,050
Uh, yeah. So where we are in our schedule.

7
00:00:37,540 --> 00:00:45,550
Right. So, yeah, basically a little over a month left, which is again, pretty wild, but we're getting there quickly.

8
00:00:45,570 --> 00:00:49,260
Right. So today, uh, we'll talk about a few different things.

9
00:00:49,290 --> 00:00:56,190
Um, so, um, we're going to return back to a couple activities and then hopefully touch on a little bit of the unconscious,

10
00:00:56,640 --> 00:01:00,990
uh, brain and then a little primer for sleep, which we'll do.

11
00:01:01,320 --> 00:01:05,310
We'll cover a bit more on Thursday when we do our EEG recordings.

12
00:01:05,670 --> 00:01:09,100
Uh, so on Thursday, we'll meet here and we'll be playing around.

13
00:01:09,120 --> 00:01:15,960
This will be our last in class activity, uh, before or at least formal pre-prepared in class activity.

14
00:01:16,440 --> 00:01:22,860
Prepared to some degree. Uh, and then we'll, we'll kind of switch modalities, I guess next the following week.

15
00:01:22,860 --> 00:01:30,390
We'll have to then but catch up session for our activity, and then we'll go into dedicated time for working on project ideas.

16
00:01:34,370 --> 00:01:45,379
Um, yeah. So, uh, for today, there's like, I'll kind of bop around to some interesting stuff that I got to attend and kind of work on over break,

17
00:01:45,380 --> 00:01:49,910
because I think y'all will find interesting as well. Um, yeah.

18
00:01:49,910 --> 00:01:54,830
And I'll just tell you about that in the slides and then, yeah, we'll get to our content.

19
00:01:57,360 --> 00:02:04,500
So the first thing I wanted to plug is that I don't know, has anyone heard of this, the Lewis College Research Day?

20
00:02:05,070 --> 00:02:10,049
Okay, see some nods. Yeah. So it's on April 11th and Friday.

21
00:02:10,050 --> 00:02:14,790
So locals here in MTC see this poster presentations.

22
00:02:15,360 --> 00:02:20,880
Abstracts are due Friday. But I wonder if people wanted to wanted to present.

23
00:02:21,420 --> 00:02:25,830
Um, maybe they were looking for something to present on their welcome to.

24
00:02:26,250 --> 00:02:31,889
You all are welcome to present on any of the activities, or use any of the data we've collected in class.

25
00:02:31,890 --> 00:02:36,090
So just open that up as yeah, another opportunity.

26
00:02:36,090 --> 00:02:41,579
If people wanted to just get some experience talking about and like pitching, uh,

27
00:02:41,580 --> 00:02:47,010
some of these neuro, uh, neuroscience concepts to, to folks so totally optional.

28
00:02:47,370 --> 00:02:52,110
Uh, but yeah, send me an email if you're interested. Uh, and I'm happy to kind of go through.

29
00:02:52,530 --> 00:03:06,550
Yeah. How we can get you there. Next, I wanted to talk about, um, a little a local conference I got to go to on, uh, Friday last Friday.

30
00:03:06,640 --> 00:03:12,830
So this was the Chicago Society for neuroscience. So I would I'm kicking myself.

31
00:03:12,880 --> 00:03:17,470
I didn't tell y'all to attend this if you wanted to. Uh, but we've hosted by.

32
00:03:17,470 --> 00:03:20,530
Yeah. Northwestern. Um, again.

33
00:03:20,530 --> 00:03:24,819
Just downtown. Uh, I would definitely recommend it if you're around next year.

34
00:03:24,820 --> 00:03:28,730
And it was. Yeah. A good mix of all different backgrounds.

35
00:03:28,750 --> 00:03:32,290
So from there was even a high schooler there that was just observing.

36
00:03:32,620 --> 00:03:41,190
Uh, but then tons of undergraduates presenting research, some folks just observing, um, some MDS, tons of different PhD.

37
00:03:41,470 --> 00:03:47,620
So, uh, it was just really cool to attend and hear about of the interesting neuroscience happening in Chicago.

38
00:03:47,620 --> 00:03:52,540
And then they brought in some really fascinating speakers, um, that I'll highlight.

39
00:03:52,810 --> 00:04:01,630
Um, uh, a few of them were talking or a handful were talking about kind of Alzheimer's disease and, uh, some really interesting,

40
00:04:01,930 --> 00:04:08,560
um, kind of predictors of Alzheimer's disease and all of these different environmental factors that contribute to it.

41
00:04:08,950 --> 00:04:16,780
And again, a mix of both doing kind of questionnaire survey data with patient outcomes, some doing live imaging.

42
00:04:17,050 --> 00:04:22,900
I thought it was just yeah, really really fascinating. Um kind of format and mix of of research.

43
00:04:23,560 --> 00:04:31,450
So yeah, one of the folks there, uh, this was Doctor Alexandra Clark, and she was, uh,

44
00:04:31,780 --> 00:04:39,520
professor of in the psych department at, um, was it, I think, UT Austin right now?

45
00:04:40,210 --> 00:04:44,020
Um, but she presented this really? Um, yeah.

46
00:04:44,020 --> 00:04:48,810
Amazing work on the mechanisms of neurocognitive aging.

47
00:04:48,820 --> 00:04:52,630
So, again, specifically, she was looking at Alzheimer's.

48
00:04:53,020 --> 00:04:56,290
Um, and she was using census census data.

49
00:04:56,710 --> 00:05:06,130
Um, as well as, you know, looking at patient outcomes for how likely are you to have to develop Alzheimer's disease later in life?

50
00:05:06,550 --> 00:05:12,040
Uh, and then breaking it down using that census data to look at correlates and predictors?

51
00:05:12,400 --> 00:05:17,970
Uh, at a level I think, uh, had like much higher resolution than we typically do.

52
00:05:17,980 --> 00:05:24,910
So getting down to like, the environmental factors, um, what neighborhood you're living in.

53
00:05:25,120 --> 00:05:28,720
Um, what access to resources do you have in that neighborhood?

54
00:05:29,020 --> 00:05:34,180
Um, and then adding in some really interesting, um, like, correlates of race.

55
00:05:34,600 --> 00:05:44,380
Um, of course, like age factor, even like, uh, family history, all of these things and kind of integrating this into like one framework.

56
00:05:44,740 --> 00:05:48,490
Um, yeah. So I thought I was, you know, really fascinated by a work.

57
00:05:48,490 --> 00:05:55,540
I think she did a great job presenting. So if folks are interested, I would definitely encourage you to take a look at her work in their her website.

58
00:05:56,800 --> 00:06:04,030
Yeah, I think it does like a mix of like clinical interviews, imaging, uh, classic like neuro psych testing,

59
00:06:04,630 --> 00:06:10,390
um, blood work, all looking at all these contributing factors to Alzheimer's disease.

60
00:06:13,520 --> 00:06:18,530
Yeah. And I want to highlight and we'll, we'll talk about this a few more times in class.

61
00:06:18,950 --> 00:06:26,150
Um, and we've covered this. We've kind of glazed over this, uh, in previous classes, but, um, so, um,

62
00:06:26,660 --> 00:06:33,360
Professor Clark was using a lot of this, uh, functional magnetic resonance imaging, so drive.

63
00:06:33,770 --> 00:06:37,579
Right? And I think we have an intuition for what this kind of data represents.

64
00:06:37,580 --> 00:06:41,330
But again, just having a slide really solidifying this.

65
00:06:41,330 --> 00:06:52,639
So these functional magnetic resonance imaging scans will measure differences in blood flow and oxygen levels, uh, around the brain and often.

66
00:06:52,640 --> 00:06:57,230
Right. So you can do that kind of at some baseline state or you can add in some stimulus.

67
00:06:57,590 --> 00:07:04,040
Right. And so this is as we know, a lot of the data in the papers we were looking at are looking at change in blood flow,

68
00:07:04,040 --> 00:07:12,710
oxygen to different regions of the brain, which is a correlate of those neurons or that region of the brain becoming more or less active.

69
00:07:14,780 --> 00:07:21,979
Right. And so that's what typically you'll have some color code, uh, where in this case it's red indicating more blood flow,

70
00:07:21,980 --> 00:07:25,790
more oxygen, meaning that these regions of the brain are becoming more active.

71
00:07:27,760 --> 00:07:37,240
Right. And so, uh, I think folks have probably or maybe have heard of, uh, Pet scans as well for positron emission tomography.

72
00:07:37,900 --> 00:07:42,910
Right. And so this is very similar idea often used um, um,

73
00:07:43,780 --> 00:07:52,660
and alternatively uh often was used before functional uh, fMRI really came, uh, to be more accessible.

74
00:07:53,050 --> 00:07:57,400
And so the idea again is we're still looking at, uh, neural activity.

75
00:07:57,790 --> 00:08:03,339
Uh, but this time we're using a tracer, a radioactive tracer that you inject into the bloodstream.

76
00:08:03,340 --> 00:08:07,989
So again, you're looking at blood flow throughout the brain, except now you're just, uh,

77
00:08:07,990 --> 00:08:13,510
using this scanning machine to actually look for that radioactive tracer in that signature,

78
00:08:13,510 --> 00:08:17,590
rather than just simply measuring changes in blood flow or oxygen.

79
00:08:18,250 --> 00:08:25,120
Right. And so, yeah, this again is showing, um, a really interesting example of how Alzheimer's disease.

80
00:08:25,120 --> 00:08:33,009
Right. You see this pretty broad and global decrease in, um, overall activity within the brain.

81
00:08:33,010 --> 00:08:37,899
And this is a really big correlate of just neurodegeneration.

82
00:08:37,900 --> 00:08:40,840
Aging and Alzheimer's is just right.

83
00:08:40,840 --> 00:08:48,520
You're seeing kind of neurons starting to die and, um, regions of the brain that were previously active becoming, uh, inactive.

84
00:08:50,950 --> 00:08:59,020
Right. And so the same idea is that you have some color map. And again, in this case, it's red, indicating a higher intensity of activity.

85
00:08:59,350 --> 00:09:03,819
Uh, and then these cooler colors like blue or purple, indicating, uh, lower activity.

86
00:09:03,820 --> 00:09:08,959
So lower blood flow, uh, to these regions. Yeah, yeah.

87
00:09:08,960 --> 00:09:13,550
Any questions I know. Yeah we we know a little bit about this already.

88
00:09:16,170 --> 00:09:21,770
Cool. So yeah, these were two imaging techniques used pretty widely at that conference.

89
00:09:21,780 --> 00:09:27,740
And that's I just wanted to highlight them again because, uh, they popped up so much and um,

90
00:09:27,750 --> 00:09:31,680
yeah, we've been covering them a lot in class, just again, giving an overview.

91
00:09:32,370 --> 00:09:38,670
Um, so this was another keynote speaker at the Chicago Society for Neurons Neuroscience conference.

92
00:09:39,090 --> 00:09:42,389
Um, he gave a really interesting talk, a broad overview.

93
00:09:42,390 --> 00:09:49,620
So she was a, uh, professor at Stanford, uh, then left to start like a nonprofit.

94
00:09:49,950 --> 00:09:56,880
And, uh, generally is doing a lot of this advocating for neuroscience education at all different education levels.

95
00:09:57,240 --> 00:10:02,700
Uh, and then actually preventing misuse of neuroscience knowledge and like, data.

96
00:10:03,030 --> 00:10:07,440
And so I know for me it was like, okay, what does that really mean?

97
00:10:07,620 --> 00:10:15,299
Well, it turns out especially she went over these really interesting examples in law and in, um, yeah,

98
00:10:15,300 --> 00:10:24,930
the legal system where people for a while, people are actually using fMRI as a way to detect if you were lying or not.

99
00:10:25,680 --> 00:10:28,350
And so, I don't know, maybe you're starting to, to, uh,

100
00:10:28,860 --> 00:10:34,440
you already can come up with ways where that like the amount of variability, the amount of noise in these systems.

101
00:10:34,800 --> 00:10:40,140
Um, if someone is maybe daydreaming whenever you take or like thinking about something else,

102
00:10:40,140 --> 00:10:48,750
how does that how how do all these variables impact, uh, the way that this, like, um, after memory is used to detect if they're lying or not?

103
00:10:49,350 --> 00:10:56,159
Uh, and so again, I encourage you if you're interested to she has like an amazing, um, uh,

104
00:10:56,160 --> 00:11:02,040
collection of studies that she has done, um, all using kind of or a lot using after Mari.

105
00:11:02,340 --> 00:11:11,850
This is one study where she took Stanford students strapped cameras to their, uh, to their necks that they had to wear for an entire semester.

106
00:11:12,240 --> 00:11:19,290
And so essentially, they were recording their lives. Uh, she then brought them after after recording their lives for a semester.

107
00:11:19,290 --> 00:11:25,530
Brockman back into the lab and then asked them a series of questions about their experience,

108
00:11:25,830 --> 00:11:31,590
basically, you know, trying to detect, um, and then there was some incentive of that.

109
00:11:31,740 --> 00:11:38,550
They can lie, but they have to report when they lie versus whether it just misremembering an event.

110
00:11:38,850 --> 00:11:47,340
And essentially, if you found correlates of, um, you know, certain brain activity whenever students are intentionally telling a lie.

111
00:11:47,730 --> 00:11:51,030
And so this is part of the data that people are misusing.

112
00:11:51,030 --> 00:11:58,140
And a lot of these, uh, kind of log cases, uh, and can be misused in, uh, kind of harmful ways.

113
00:11:59,490 --> 00:12:05,460
Uh, and so she went on to publish, uh, subsequent study, which was essentially how to beat this lie detector.

114
00:12:05,790 --> 00:12:10,409
So essentially showing that this data can be easily fabricated by, um,

115
00:12:10,410 --> 00:12:16,350
coaching students as to, uh, either be in a more relaxed state, basically how to,

116
00:12:16,440 --> 00:12:21,900
you know, activate other regions of the brain that were initially picked up as correlates of,

117
00:12:22,140 --> 00:12:25,890
of, um, whenever students are actually telling these lies.

118
00:12:26,550 --> 00:12:35,730
So again, just I know some really interesting, um, research and some, you know, interesting misuses of neuroscience in,

119
00:12:35,970 --> 00:12:43,860
you know, not just, uh, understanding the brain, but, you know, applied in kind of harmful ways in the judicial system.

120
00:12:44,700 --> 00:12:49,620
Yeah. So that was all kind of in the Chicago Science Society for neuroscience conference.

121
00:12:49,620 --> 00:12:53,520
I thought that that was interesting to y'all. Um, yeah.

122
00:12:53,550 --> 00:12:57,330
And so feel free to look at more of the publications from these folks.

123
00:13:00,210 --> 00:13:04,170
All right. And then I wanted to do a little follow up from last week.

124
00:13:04,170 --> 00:13:12,180
So also during spring break, I encountered a few, um, kind of like pop science articles, and I was listening to a podcast.

125
00:13:12,750 --> 00:13:21,810
Um, so I listened to shortwave, uh, which I think is also a really nice, um, podcast for just broad science ideas.

126
00:13:22,230 --> 00:13:25,770
Uh, this one, they packed a lot in. I think it was like seven minutes.

127
00:13:26,190 --> 00:13:29,780
Um, but what I wanted to highlight is. Right bird speech.

128
00:13:29,790 --> 00:13:35,130
Right. We were talking about that at the in the class, uh, uh, before spring break.

129
00:13:35,400 --> 00:13:41,450
Um, and you know how they're very common, especially zebra finches are very common model organism, uh,

130
00:13:41,490 --> 00:13:49,110
for how we generate speech, uh, and the correlates of, uh, and, or the, uh, tissues within our brain that become active.

131
00:13:50,220 --> 00:13:53,220
Um, and so just after our class,

132
00:13:53,220 --> 00:14:01,020
there was a new paper that was published in this is called Convergent Vocal Representations in parrot and Human forebrain motor Networks.

133
00:14:01,500 --> 00:14:09,870
And so essentially what this paper is doing, um, essentially they're advocating that their parents are a better, um,

134
00:14:09,870 --> 00:14:22,140
system for understanding, um, vocal communication in the uh, generation of, um, kind of words, syllables than zebra.

135
00:14:22,230 --> 00:14:29,160
Um. Uh, why am I blinking our zebra finches?

136
00:14:29,430 --> 00:14:33,500
I kept wanting to say fish. I was like, they're not fish. Um, yeah.

137
00:14:33,510 --> 00:14:37,770
And so I again, this is just a little preview, but of of the paper.

138
00:14:38,040 --> 00:14:45,930
Um, but this first part of the figure is actually kind of classifying, taking, um,

139
00:14:46,440 --> 00:14:54,390
a collection of sentences in which someone is using specifically this word invaded in this is human speech.

140
00:14:54,750 --> 00:14:57,299
And so all this graph, uh,

141
00:14:57,300 --> 00:15:05,700
part B is doing is showing how the similarity and how similar this sentence structure is across all of these different use cases.

142
00:15:07,110 --> 00:15:14,040
Um, right. And then this top graph is just showing how you can actually represent that vocal information.

143
00:15:14,040 --> 00:15:19,500
Right. And these are spectrograms where you have frequency on the y axis and time on the x axis.

144
00:15:20,250 --> 00:15:23,280
And so next we looked at uh they looked at zebra finches.

145
00:15:23,730 --> 00:15:28,110
Right. And so again the key idea of this figure is comparing B to d.

146
00:15:28,380 --> 00:15:34,290
And you can see that you don't really have this continuous space and use of syllables.

147
00:15:34,290 --> 00:15:41,940
They're almost, uh, kind of truncated, where I guess you're having um, very different sentence structure,

148
00:15:42,180 --> 00:15:50,490
even though there may be some overlap in like, uh, or sentence meaning in the overlap of, uh, kind of, uh, syllables that are used.

149
00:15:51,630 --> 00:15:55,410
And this is for zebra finches. And then finally we get to our parrots.

150
00:15:55,410 --> 00:16:04,379
These are parakeets. And so they're arguing that this, uh, you know, warble syllables or like,

151
00:16:04,380 --> 00:16:13,860
sentence structure is more closely representative of human speech than, uh, what was previously thought for zebra finches.

152
00:16:14,130 --> 00:16:16,860
And then they go on to categorize areas of the brain.

153
00:16:16,860 --> 00:16:28,890
They show that there are even more, uh, overlap in um, like auditory cortex in, in, uh, auditory audio information processing than in the zebra finch.

154
00:16:29,280 --> 00:16:36,600
Um, and so, yeah, they argue that we should be using parakeets as our core model organism for understanding speech patterns.

155
00:16:37,350 --> 00:16:43,920
Um, yeah. So that again, just came out a couple days after we went over this in class, which I thought was really interesting.

156
00:16:44,190 --> 00:16:52,829
And then here's a little picture from, uh, their actual experiment, where, again, we kind of went over a diagram last class, but again,

157
00:16:52,830 --> 00:17:01,890
we have, uh, audio recording and then, uh, actual electrode recording, um, from these different regions of the brain within our parakeets.

158
00:17:04,860 --> 00:17:08,070
Cool. All right.

159
00:17:08,580 --> 00:17:14,310
So now kind of continuing on my little randomly cobbled intro here.

160
00:17:14,610 --> 00:17:21,540
Uh, so this is going this was the very last thing we covered in our last class, right?

161
00:17:21,540 --> 00:17:26,550
So we were playing around with this idea of how might sleep impacts speech patterns.

162
00:17:27,000 --> 00:17:28,680
And so we, um,

163
00:17:28,680 --> 00:17:37,379
this was a prompt from in the class for my hypothesis for how increase or decrease sleep may impact communication based on what we've covered.

164
00:17:37,380 --> 00:17:42,690
And then, uh, think about using lecture transcripts from me talking as the data.

165
00:17:42,690 --> 00:17:50,280
And then can we pick out words or phrases that you might see, uh, correlate across more or less sleep?

166
00:17:50,640 --> 00:17:56,700
So I went back and I kind of updated this. So we're kind of we'll play around with this for a second.

167
00:17:56,700 --> 00:18:09,840
And you're welcome to, to follow along. Um, but again, uh, I think what I've been, I got kind of obsessed with this for like the next couple of days.

168
00:18:10,450 --> 00:18:17,759
And I was trying to find what words were actually correlating, and I was able to take some of the suggestions that came up during class,

169
00:18:17,760 --> 00:18:21,540
and I was able to actually integrate that into, uh, the coding framework.

170
00:18:23,250 --> 00:18:27,660
But, um, reminder of this, this kind of paper idea.

171
00:18:28,020 --> 00:18:32,750
Uh, the idea is that, um, sleep deprivation leads to, uh,

172
00:18:32,760 --> 00:18:42,000
some changes in communication performance during instructive tasks, while simpler word, uh, descriptions appear resilient.

173
00:18:42,420 --> 00:18:49,770
So then, yeah, start to think and know we we did this before and this is I'll have a better read out now so I can start

174
00:18:49,770 --> 00:18:56,340
to think of what words could be in more instructive that may be coming out of my mouth at some point.

175
00:18:56,760 --> 00:19:03,270
And then what are maybe basic, simpler word descriptions that you might think to be resilient?

176
00:19:03,990 --> 00:19:07,080
Okay. So we'll hop out of this for a second.

177
00:19:07,080 --> 00:19:13,590
And yeah, you're welcome. If you go to the GitHub or um, I think it's linked in.

178
00:19:17,770 --> 00:19:22,880
Yeah. Last classes that, uh. Yeah.

179
00:19:23,600 --> 00:19:27,649
So if you go to the canvas yeah.

180
00:19:27,650 --> 00:19:33,830
You can click on here. I think I have it up here. All right.

181
00:19:36,050 --> 00:19:43,459
Yeah. So this is, um. So I made some updates to make it a little bit easier if someone, if people want to play around with it.

182
00:19:43,460 --> 00:19:51,230
And I thought it was just a really interesting way of kind of exploring, uh, some of these ideas that we, uh, we're talking about.

183
00:19:51,830 --> 00:20:00,020
Um, okay. So the default phrase I have in here is cool, but does anyone have think of, um,

184
00:20:00,290 --> 00:20:08,300
maybe a more instructive phrase, even phrase or word that maybe I might say during class?

185
00:20:09,420 --> 00:20:13,730
You can tell it. Yeah. Chat about it with people for, you know, a few seconds.

186
00:20:23,670 --> 00:20:27,070
Yeah I agree. It's one of your vacations.

187
00:20:27,480 --> 00:20:39,750
Yeah. I mean, not the main one, but I guess since these are.

188
00:20:45,300 --> 00:20:48,880
So if I'm sitting right where you're right.

189
00:20:54,230 --> 00:21:08,080
These testimonies. Yeah.

190
00:21:08,610 --> 00:21:13,110
Any ideas? First one to try. What about the.

191
00:21:13,710 --> 00:21:22,200
Okay. Yeah, that's a good one. All right. So would that fall into our instructional or more just general simple word.

192
00:21:22,800 --> 00:21:25,950
I guess the thought process is that if you end up stuttering.

193
00:21:26,370 --> 00:21:29,790
Yeah, there might be one of those. Yeah, that's a good, good thought.

194
00:21:29,820 --> 00:21:33,080
Okay. So again, people can play around with the ideas.

195
00:21:33,090 --> 00:21:37,740
You can just use this block here to change whatever where you're interested in looking up.

196
00:21:38,550 --> 00:21:43,340
So phrase. Um, and then I added a few more lectures as well.

197
00:21:43,350 --> 00:21:49,080
So we have a bigger data set. I should have added lecture from last Friday or last Thursday.

198
00:21:49,830 --> 00:21:51,510
Um, okay.

199
00:21:51,510 --> 00:22:01,680
And then so what it's doing is it uses, um, as a baseline because I thought, I think that came out as being what we thought would be a good predictor.

200
00:22:02,130 --> 00:22:09,390
Uh, and then I normalized sleep. So I'm not going to again tell you how much sleep I got, but, uh, with negative being,

201
00:22:09,390 --> 00:22:14,250
uh, less sleep and one being, uh, the most high levels of sleep, so we don't.

202
00:22:14,610 --> 00:22:19,490
Maybe there's a trend. Um, yeah, actually, there could be a trend, right?

203
00:22:19,510 --> 00:22:28,919
If we were to maybe increase the the ins here. Um, and so I have a few more plots I added in here to really look at this.

204
00:22:28,920 --> 00:22:33,959
So the next thing is looking at, um, a linear correlation.

205
00:22:33,960 --> 00:22:42,360
So seeing if there is a positive trend and is it significant across, uh, how much sleep someone has or I've received.

206
00:22:43,110 --> 00:22:52,230
Uh, and so interestingly I, you don't see there is a correlation but not significant, which could just be, you know, we need more data.

207
00:22:52,650 --> 00:22:56,970
So I'll try and add more, uh, transcripts in here. But yeah. So there's a positive trend.

208
00:22:57,270 --> 00:23:08,249
And so this would but in the direction you wouldn't think of more sleep means more of these more using the word the um,

209
00:23:08,250 --> 00:23:14,760
and so yeah, one question and maybe I'll just continue through this a bit more.

210
00:23:16,050 --> 00:23:24,690
Um, so the next thing I think someone mentioned is like looking at the average length of sentences.

211
00:23:25,410 --> 00:23:29,100
So how long maybe I'm using more complex larger.

212
00:23:29,130 --> 00:23:32,220
Uh, yeah. Strung together sentences across sleep.

213
00:23:32,220 --> 00:23:37,620
Or it could be more. Oh, it was like rambling with less sleep, which I would have thought true.

214
00:23:38,040 --> 00:23:41,160
But again, there's this negative correlation with average length.

215
00:23:41,400 --> 00:23:46,650
Length of sentences, uh, versus um when I've had more sleep.

216
00:23:46,650 --> 00:23:53,880
So it sounds like I'm actually talking more and forming longer sentences when I have had more sleep.

217
00:23:54,630 --> 00:24:03,480
Um, okay. And then this last bit is looking at the average, which again, makes sense.

218
00:24:03,480 --> 00:24:07,380
The average number of words per sentences across sleep.

219
00:24:07,500 --> 00:24:14,550
So again this positive increase showing that there's just more information coming out of my mouth when I have more sleep.

220
00:24:15,870 --> 00:24:24,599
Uh, and then okay, so the last bit someone mentioned the duration of each sentence.

221
00:24:24,600 --> 00:24:31,920
So what's really cool about these transcripts is that they're broken up into sentences and each sentence has a timestamp on it.

222
00:24:33,120 --> 00:24:37,800
Um, and so we actually could get that data on how long each sentence takes.

223
00:24:40,390 --> 00:24:44,860
Uh, yeah. And again, we don't see a correlation really.

224
00:24:45,070 --> 00:24:49,210
Yeah. This last point is just showing that. Yeah. Sentences maybe take a little bit longer.

225
00:24:49,570 --> 00:24:53,530
Um, we I have normalized sleep. So again I don't know.

226
00:24:53,760 --> 00:24:57,870
To me it kind of stuck out as being an interesting. Yeah.

227
00:24:57,880 --> 00:25:00,100
Maybe this kind of validating this paper.

228
00:25:00,100 --> 00:25:07,480
If all of this shows that most of my speech is unaffected, or maybe there's a trend, but again, we'd need more data.

229
00:25:08,080 --> 00:25:19,990
Um, but then this last, uh, thing I was looking at is I was thinking of you being potentially more of an in kind of instructive,

230
00:25:20,770 --> 00:25:29,079
uh, word that I might use. And so you see this really strong kind of like, again, I think, you know,

231
00:25:29,080 --> 00:25:34,810
this might just be noise, but almost perfect correlation between lack of sleep.

232
00:25:35,260 --> 00:25:38,440
Um, so sentences that I, uh,

233
00:25:39,010 --> 00:25:48,580
instructive sentences that use you take much longer to come out of my mouth when I have less sleep than when I've had more sleep,

234
00:25:49,030 --> 00:25:52,240
which, again, could fit with this idea from the paper.

235
00:25:54,210 --> 00:25:57,570
Of how sleep might impact speech patterns.

236
00:25:58,350 --> 00:26:09,360
Um. Right where the simpler word descriptions may be resilient, but instructive tasks like I want you to do x, y, z could take more.

237
00:26:09,360 --> 00:26:14,969
So again, hopefully this gives you. And if you have another suggestion, I'm happy to explore it now.

238
00:26:14,970 --> 00:26:17,970
Or you can do it on your own of interesting words.

239
00:26:18,450 --> 00:26:25,829
Um, but yeah, hopefully. And again, for anyone that's looking at doing any kind of like text parsing for final projects,

240
00:26:25,830 --> 00:26:34,740
hopefully this again kind of gives you an example of what you can do with that, what kind of correlates you can look at.

241
00:26:35,250 --> 00:26:43,500
And hopefully it's clear how that can relate back to, um, neuroscience through sleep and through kind of cognition.

242
00:26:47,980 --> 00:26:53,290
Cool. Yeah. Any last words? People want me to run. No.

243
00:26:55,450 --> 00:27:00,230
Uh uh. Cool.

244
00:27:00,260 --> 00:27:08,810
All right. All right.

245
00:27:08,830 --> 00:27:15,040
And so also now this brings us back in our again roundabout intro.

246
00:27:15,310 --> 00:27:19,000
Um, to you know, that was part of our activities.

247
00:27:19,000 --> 00:27:24,819
We'll have that in our write up coming um, in a couple of weeks where, again,

248
00:27:24,820 --> 00:27:30,850
you'll just be really kind of coming up using these, coming up with an answer for these two points.

249
00:27:31,180 --> 00:27:35,919
So form a hypothesis. And then if you want you can explore that that data set.

250
00:27:35,920 --> 00:27:43,060
But essentially just um, thinking about, you know, these ideas of what could be correlates with,

251
00:27:43,330 --> 00:27:47,410
um, more or less sleep, uh, in terms of kind of speech patterns.

252
00:27:49,360 --> 00:27:54,850
Um, but then we have an upcoming, uh, write up for activities six and seven.

253
00:27:55,150 --> 00:28:03,520
So I change, I push this back a day and I'm curious what people are thinking about this, but yeah, this is due now Friday at the end of the day.

254
00:28:03,880 --> 00:28:07,210
Um, and so this is the write up for activity six and seven.

255
00:28:07,810 --> 00:28:15,880
So six was, uh, looking our, uh, electrophysiology, neuro electrophysiology in our bumblebees.

256
00:28:16,330 --> 00:28:23,200
Uh, and then seven was, uh, kind of thinking about creating an associative learning task in our bumblebees.

257
00:28:25,930 --> 00:28:29,800
Um, and I think. Yeah. Not compared to our previous write ups.

258
00:28:30,310 --> 00:28:38,430
This one, I think is a little bit lighter. Um, when I did receive, I got a couple of emails that I had.

259
00:28:38,440 --> 00:28:42,999
I was supposed to generate some stock figures which are now populated in that folder.

260
00:28:43,000 --> 00:28:46,000
If you, uh, navigate there, you should see those.

261
00:28:46,360 --> 00:28:52,270
Um, and then, yeah, I think you just have a few sentences to describe.

262
00:28:52,780 --> 00:28:57,280
Um, again, the hypothesis and the results for each of these.

263
00:28:57,610 --> 00:29:03,070
Uh, and then essentially, you know, what kind of went wrong for our associative learning activity,

264
00:29:03,370 --> 00:29:06,820
uh, and kind of brainstorming ways to improve it kind of going forward.

265
00:29:08,710 --> 00:29:17,740
Um, but this also brings us to, I updated and caught a bunch of errors in the electrophysiology analysis.

266
00:29:18,160 --> 00:29:23,830
Um, and added, I think something that, yeah, I think is pretty interesting and kind of relates.

267
00:29:24,310 --> 00:29:31,240
Uh, this was kind of inspired by the the Chicago Society for neuroscience, uh, conference and some of the work I saw there.

268
00:29:31,240 --> 00:29:40,570
But I think it kind of pulls out, uh, some really interesting, uh, features of like, neuron spiking that we didn't previously had.

269
00:29:41,980 --> 00:29:48,430
So for this, I want to kind of go back to our lecture two review.

270
00:29:48,760 --> 00:29:54,970
So thinking of an action potential right where rapid and temporary change in membrane potential.

271
00:29:55,390 --> 00:30:03,610
Um, right. And when neurons are stimulated, they, and they, um, stimulate above a certain threshold rate, they'll depolarize.

272
00:30:04,330 --> 00:30:12,430
Um, and so right. This is what we went over early in lecture two where you have some resting membrane potential that's,

273
00:30:12,730 --> 00:30:16,150
uh, negative somewhere around like -67 millivolts.

274
00:30:16,780 --> 00:30:21,459
Uh, if, uh, you have some input that exceeds a threshold,

275
00:30:21,460 --> 00:30:28,630
you'll get this depolarization and that membrane potential will move positively towards and above zero.

276
00:30:28,900 --> 00:30:32,230
And then you'll get this repolarization phase in hyper polarization.

277
00:30:33,310 --> 00:30:37,150
Cool. Oh. All right.

278
00:30:37,390 --> 00:30:42,910
So now we'll take a second. And we then this is kind of expanding that idea.

279
00:30:43,390 --> 00:30:51,060
So during our electrophysiology experiments we were not measuring inside of a neuron per se.

280
00:30:51,070 --> 00:31:00,760
Remember we were taking kind of broad um electrophysiology measurements within the brain of changes in voltage.

281
00:31:00,760 --> 00:31:04,360
Right. So these were extracellular changes in voltage.

282
00:31:04,870 --> 00:31:11,890
Um, what knowing that this is so this is what happens within our cell during depolarization.

283
00:31:12,460 --> 00:31:20,800
If we were to measure, uh, extracellular, um, voltage outside of that cell, what do you think?

284
00:31:21,160 --> 00:31:28,300
Uh, do you think that the change in voltage would be the same, um, trending in a similar direction?

285
00:31:28,310 --> 00:31:32,560
Would it be opposite? Would it be in. Would there be an increased magnitude?

286
00:31:32,920 --> 00:31:41,380
What do you think the difference between extracellular shown here and intracellular based on um,

287
00:31:42,190 --> 00:31:45,790
thinking about what how would the polarization occurs.

288
00:31:46,510 --> 00:31:49,570
Um, what causes that depolarization.

289
00:31:50,110 --> 00:31:55,030
Um, and how that might affect extracellular fluid around a random neuron.

290
00:31:55,360 --> 00:32:02,259
So think about that for like a minute. You can talk with your neighbor and then yeah we'll reveal the answer.

291
00:32:02,260 --> 00:32:08,740
And then I think we'll show you some. I'll show you some interesting data that you all collected that kind of validate that.

292
00:32:45,130 --> 00:32:48,760
What do you think? I don't know.

293
00:32:49,090 --> 00:32:53,370
I think the extracellular membrane should also be there.

294
00:32:54,400 --> 00:33:02,110
Right. Um, and because a lot of similar ions within that space and.

295
00:33:02,150 --> 00:33:09,720
Okay, okay. Because there's like an exchange of ions right from the picture letter to the interest.

296
00:33:10,090 --> 00:33:15,370
Yeah. Wait, um, if.

297
00:33:18,280 --> 00:33:24,580
So it's three sodium in and two potassium out three sodium in two potassium out.

298
00:33:24,630 --> 00:33:28,480
But that's with the electrochemical gradient. Yeah.

299
00:33:28,540 --> 00:33:34,839
Um well let's see. Well, so I guess there's some pretty broad.

300
00:33:34,840 --> 00:33:40,149
It depends on what for depolarization. Some pretty broad changes.

301
00:33:40,150 --> 00:33:44,380
So sometimes there's like chloride that will leave your cell.

302
00:33:44,800 --> 00:33:51,250
Um but yeah some. So at baseline I always think of like a banana which I.

303
00:33:51,250 --> 00:33:55,899
Yeah. With I know bananas have a ton of potassium. It's so like within the peel.

304
00:33:55,900 --> 00:34:01,000
So there's at baseline high amounts of potassium within your cell.

305
00:34:01,210 --> 00:34:04,390
So when you depolarize you're getting a lot of that potassium leaving.

306
00:34:05,080 --> 00:34:16,190
Yep. Sodium. And then yeah um on yeah some sodium enters and then that is rebalanced when you're getting uh, repolarization.

307
00:34:16,210 --> 00:34:22,810
Yeah. Yeah. So yeah the extracellular environment should the difference to me.

308
00:34:27,940 --> 00:34:31,960
Um. All right. Anyone have some thoughts they want to share?

309
00:34:32,110 --> 00:34:38,440
Take a guess. Yeah.

310
00:34:42,890 --> 00:34:47,080
It's like I'm reading from the iron, switching right inside to outside.

311
00:34:47,090 --> 00:34:50,320
So I should be like. Yeah.

312
00:34:50,980 --> 00:34:55,780
Anyone else have any contrasting ideas or ideas they want to share?

313
00:35:01,680 --> 00:35:07,980
Aw. Yeah. Yeah. So that. Yeah, that's essentially it, which is kind of counterintuitive, right.

314
00:35:08,100 --> 00:35:14,820
Or I think it's intuitive, but we often we learn about depolarization and we just think about, um,

315
00:35:15,120 --> 00:35:22,110
you know, during depolarization, you're moving, um, towards a more positive state in voltage.

316
00:35:22,440 --> 00:35:28,710
But if you're actually taking extracellular recordings, you're measuring, uh, the opposite effect.

317
00:35:28,720 --> 00:35:38,400
So you're actually measuring a decrease in overall voltage from, uh, more negative ions or a change in ion balance.

318
00:35:38,760 --> 00:35:43,590
Uh. Extracellular versus intracellular.

319
00:35:43,830 --> 00:35:48,360
So if you're within your cell you're moving more positive outside your cell.

320
00:35:48,360 --> 00:35:52,200
Your neuron is going to actually be more negative. So that's exactly it.

321
00:35:52,200 --> 00:35:57,180
So in this little diagram here. So at the bottom right this is your extracellular electrode.

322
00:35:57,480 --> 00:36:03,270
And there's a whole host of ways that in uh varieties of extracellular electrodes.

323
00:36:03,480 --> 00:36:04,890
But for the most part right.

324
00:36:05,250 --> 00:36:13,920
When you see this depolarization phase shown here, that's where you actually get, um, a decrease in overall membrane potential, right?

325
00:36:13,920 --> 00:36:15,840
Becoming more negative, uh,

326
00:36:15,840 --> 00:36:24,780
in that extracellular space as more you're giving that a more negative or changes in ion concentration that's more negative outside your, your neuron.

327
00:36:25,680 --> 00:36:29,830
Yeah. Yeah.

328
00:36:30,010 --> 00:36:32,220
So exactly as yeah,

329
00:36:32,260 --> 00:36:38,800
our extracellular fluid actually becomes more negative while the intracellular fluid becomes more positive during that depolarization event.

330
00:36:39,580 --> 00:36:46,600
And so knowing that we can actually go back here.

331
00:36:49,410 --> 00:36:55,260
Yeah. So I updated our, um, electrophysiology kind of analysis code.

332
00:36:55,800 --> 00:37:03,090
Uh, so, um, I think this is, again, also a little bit easier to work through, and I think I fixed most of the errors.

333
00:37:04,470 --> 00:37:09,000
Um, yeah. And I updated this link in the canvas as well.

334
00:37:19,260 --> 00:37:29,450
Cool. All right.

335
00:37:29,630 --> 00:37:34,320
Yeah. So downloading the GitHub analysis.

336
00:37:34,340 --> 00:37:41,180
Okay. So the first thing. So now we can it's a little easier to select from our different uh conditions that we use.

337
00:37:41,720 --> 00:37:48,830
Uh we ran experiments over um so it does anyone have a particular experiment they want to look at?

338
00:37:54,660 --> 00:37:58,560
Blue light. Yeah. Let's do it. Cool.

339
00:37:58,830 --> 00:38:04,469
All right. So, yeah, the idea you can select it, run, uh, the first thing.

340
00:38:04,470 --> 00:38:12,180
So this is still similar to what we had done before. So adding a, a filter for, um, noise that could be in our data.

341
00:38:13,110 --> 00:38:17,459
This is just, um, kind of it's the data is kind of truncated in a weird way.

342
00:38:17,460 --> 00:38:28,500
This is me fixing it and kind of concatenating it and making it a very long, kind of nice, clean, um, um, experimental recording across.

343
00:38:28,500 --> 00:38:36,060
I think it was like 10s or so. And so this next plot is going to show the raw data with a new feature.

344
00:38:38,990 --> 00:38:42,860
Okay, so this should look somewhat familiar.

345
00:38:43,040 --> 00:38:46,210
So here we have yeah raw data. Um, right.

346
00:38:46,280 --> 00:38:53,060
We're seeing all these changes in amplitude and frequency, uh, which we think our neural activity is buried somewhere in there.

347
00:38:53,660 --> 00:39:02,900
Um, so what we've done now is looking we know that, ah, whenever we're seeing, uh, depolarization within a neuron,

348
00:39:03,200 --> 00:39:08,900
we should see again, uh, a change in extracellular voltage that's going to be more negative.

349
00:39:09,170 --> 00:39:17,660
So looking for the most, um, negative peaks within this data could allow us to pull out, um,

350
00:39:19,610 --> 00:39:26,720
potentially individual spikes or just periods where we're seeing a lot more depolarization happening, uh, within the brain.

351
00:39:26,960 --> 00:39:33,980
Right. So just again, using that idea, we went over of electro extracellular recordings will be more negative when

352
00:39:34,250 --> 00:39:39,230
depolarization is happening to just pull out the peaks of these very negative,

353
00:39:39,380 --> 00:39:50,290
um, uh, changes. Okay, so the next thing we're going to do is just take all of these isolated events and then try and over,

354
00:39:50,290 --> 00:39:54,340
um, take an average of them and kind of synchronize them so we can look at,

355
00:39:54,880 --> 00:40:03,970
um, the kind of waveform of our, uh, spike to see if this actually fits with a lot of the data we've been looking at.

356
00:40:09,670 --> 00:40:13,420
Cool. All right. Yeah.

357
00:40:13,420 --> 00:40:17,050
So at least. Yeah. So it's a little messy, but.

358
00:40:17,320 --> 00:40:24,969
Right. So this, uh, the light lines are all of our kind of recorded events, uh, synchronized right at the center point.

359
00:40:24,970 --> 00:40:33,250
And we see a pretty big decrease in overall activity at that point, which could be, again, indicative of, you know, a spike actually occurring.

360
00:40:33,940 --> 00:40:45,580
Uh, this is just one example. And then this is going to run across, um, I think of all of the presentations within that, um, the blue test data.

361
00:40:46,240 --> 00:40:50,800
And so now we have because I think there's like ten different presentations.

362
00:40:51,910 --> 00:40:55,750
Right. So these are the averages across all of those presentations.

363
00:40:55,750 --> 00:41:02,620
Right. So you're starting to see what looks like real signal um coming out and we call this spike sorting.

364
00:41:03,190 --> 00:41:11,229
Um, and this was we were able to do this you a relatively simple way of again, just finding the peaks and, you know,

365
00:41:11,230 --> 00:41:18,130
negative peaks of those spikes and then essentially aligning them and then looking at this small window, um, in time.

366
00:41:21,560 --> 00:41:30,730
Cool. And then this next is going to, I think take the average of all of those.

367
00:41:31,120 --> 00:41:39,490
Right. And so this is essentially what, uh, the average response to that blue light looks like again, it's, you know, even looking more clear.

368
00:41:40,600 --> 00:41:48,130
Um, and then these next two plots are just comparing loop got take this out.

369
00:41:51,960 --> 00:41:56,130
Um, the number of detected spikes. Uh, within five seconds.

370
00:41:56,130 --> 00:42:03,590
So this is something you can use to compare, um, different, uh, stimulus presentations, uh, across each other.

371
00:42:03,600 --> 00:42:08,430
So a natural comparison of this red light would be, uh, to blue light would be the red light.

372
00:42:09,270 --> 00:42:16,620
Um, so, right, this is one of the features that we, we thought would be interesting to compare across, so than the number of spikes,

373
00:42:16,800 --> 00:42:19,740
which we think would increase if you're stimulating,

374
00:42:19,740 --> 00:42:25,319
if you're presenting a stimulus that activates the region of the brain that we're measuring changes in electric.

375
00:42:25,320 --> 00:42:28,350
Uh, yeah. Voltage within.

376
00:42:28,770 --> 00:42:32,729
And then the last graph here is, uh, the mean amplitude.

377
00:42:32,730 --> 00:42:38,820
So another metric that you can use to compare, um, across different stimulus presentations.

378
00:42:39,330 --> 00:42:44,760
So I went through and added a bunch of these figures into the linked folder in canvas too.

379
00:42:44,760 --> 00:42:50,670
So you can just grab some of these if you want. Or you can play around with this yourself.

380
00:42:51,270 --> 00:42:57,389
Um, either. It's totally fine. Um, I'll do one more that I thought was interesting.

381
00:42:57,390 --> 00:43:07,140
So looking at we're going to look at heat. So actually cooling down our animals and then looking at a baseline neural activity.

382
00:43:09,050 --> 00:43:15,540
Right. So that looks good. Isolating the spikes. Yeah.

383
00:43:15,540 --> 00:43:19,080
So this is looking, you know, even more clean.

384
00:43:20,430 --> 00:43:28,709
Right. So this really nice depolarize our depolarization and then maybe even starting to see this hyper polarization.

385
00:43:28,710 --> 00:43:46,240
Right. As you're getting the opposite effect right after. Right.

386
00:43:46,250 --> 00:43:50,239
And so this is starting to look. Yeah. Actually really nice.

387
00:43:50,240 --> 00:43:52,490
Right. This really clean, um,

388
00:43:53,450 --> 00:44:00,920
looks like depolarization measured through extracellular recordings and then potentially this hyper polarization happening right here.

389
00:44:01,850 --> 00:44:09,350
Right. So yeah your through your data you're able to almost resolve, you know, trends single spike trends.

390
00:44:09,740 --> 00:44:12,950
Um, you know within uh the beats.

391
00:44:13,190 --> 00:44:22,280
Right. So I thought that was again really cool. And hopefully it gives folks ideas of, you know, how to process data in experiments.

392
00:44:22,280 --> 00:44:32,270
And then for this last right up, uh, you can use this data, which are these figures which I think are much cleaner than our previous figures.

393
00:44:33,680 --> 00:44:43,550
Cool. Cool.

394
00:44:44,060 --> 00:44:47,360
Yeah. And then yeah, hopefully especially that last figure.

395
00:44:47,360 --> 00:44:55,099
Right. It looks really similar to, you know, this very simple diagram here of what a canonical extracellular spike could look like.

396
00:44:55,100 --> 00:44:59,090
So um yeah I thought that was cool. All right.

397
00:44:59,720 --> 00:45:02,980
Moving right along. All right.

398
00:45:02,990 --> 00:45:08,000
So, um, we'll talk a little bit about, um, some new stuff.

399
00:45:08,000 --> 00:45:16,940
So thinking about kind of unconscious brain and neural activity that kind of happens, uh, more without, you know, our thought.

400
00:45:17,090 --> 00:45:23,659
And this isn't these aren't new ideas because we've been a lot of the, um,

401
00:45:23,660 --> 00:45:29,270
circuits we've been talking about, um, can be considered part of our, you know,

402
00:45:29,270 --> 00:45:34,790
unconscious brain and, um, unconscious kind of circuits and part of, uh,

403
00:45:34,820 --> 00:45:40,430
just general information processing that we do just naturally without top down control.

404
00:45:42,140 --> 00:45:50,420
Right. And so as a little review of kind of where, um, you know, unconscious, conscious thought can live in,

405
00:45:50,840 --> 00:45:56,390
um, you know, mapping out kind of the different, uh, topics we've covered so far.

406
00:45:56,810 --> 00:45:57,020
So.

407
00:45:57,020 --> 00:46:04,160
Right, generally we've been talking about, you know, the nervous system we started with the peripheral nervous system being our sensory perception,

408
00:46:04,550 --> 00:46:10,730
how that's integrated right into the central brain. Um, that's through the spinal cord.

409
00:46:10,910 --> 00:46:17,490
Uh, we then started to break that down into our somatic nervous system in our, uh,

410
00:46:17,780 --> 00:46:26,389
autonomous auto autonomic nervous system, uh, which are somatic, is communicating with our sensory organs.

411
00:46:26,390 --> 00:46:31,250
Right. And that the big thing is right. This is what we canonically think of as top down control.

412
00:46:31,670 --> 00:46:35,600
So voluntary control of muscles of actions.

413
00:46:36,110 --> 00:46:45,860
Uh, well, this, uh, autonomous other autonomic nervous system, uh, is more this communication with our internal organs and glands.

414
00:46:45,860 --> 00:46:55,340
Right. So now getting into this, you know, structure, nervous system that is running in the background without a ton of conscious thought.

415
00:46:56,750 --> 00:46:58,010
Right. And then exactly.

416
00:46:58,010 --> 00:47:07,640
We broke that down into looking at these sensory, uh, efferent nervous system sensory input and our motor output as efferent copies.

417
00:47:08,660 --> 00:47:20,989
Um, and then we can break down the autonomic nervous system into both, uh, sympathetic and then parasympathetic sympathetic division of,

418
00:47:20,990 --> 00:47:27,950
uh, our nervous system with sympathetic being more of this arousal, more excitement, more motivation.

419
00:47:28,280 --> 00:47:38,750
Um, the parasympathetic sympathetic. Kind of doing the opposite and leading to the, uh, more calming, uh, overall states.

420
00:47:40,820 --> 00:47:44,969
Right. Right.

421
00:47:44,970 --> 00:48:00,000
And so, um, trying to measure this, um, kind of unconscious, unconscious, um, kind of activity within the brain, um, and kind of what our,

422
00:48:00,000 --> 00:48:07,170
our bodies look at or our brains look like when they're at rest and we're not doing a really direct,

423
00:48:07,650 --> 00:48:14,130
um, kind of motivated task can fall into this idea of the default mode network.

424
00:48:14,580 --> 00:48:19,799
And so this is the idea of kind of baseline neural activity, uh,

425
00:48:19,800 --> 00:48:26,910
when folks are in kind of a relaxed state and this describes connectivity between, uh, a few core regions.

426
00:48:27,390 --> 00:48:34,980
Um, so the dorsal medial prefrontal cortex, uh, posterior cingulate cortex and then this angular gyrus.

427
00:48:35,400 --> 00:48:46,080
So all of these are canonically included in kind of what regions of our brain are becoming active or maintaining activity as we're in this,

428
00:48:46,080 --> 00:48:50,100
uh, really kind of baseline, um, state.

429
00:48:50,790 --> 00:48:59,519
And so often when we're thinking about or looking at, uh, fMRI data and that's what's shown here on the right, um,

430
00:48:59,520 --> 00:49:08,220
often, uh, experiments are making a comparison to some kind of default mode network as some kind of baseline.

431
00:49:08,970 --> 00:49:14,490
Um, and again, this is just able to incorporate a lot of these kind of unconscious,

432
00:49:14,880 --> 00:49:21,480
uh, actions that we are performing, um, without a ton of conscious thought.

433
00:49:26,470 --> 00:49:28,930
Cool. Um, and so.

434
00:49:29,500 --> 00:49:40,000
Right, one way of kind of measuring these type of, uh, that coarse level of, um, neural activity is using an electro and cephalic graph.

435
00:49:40,720 --> 00:49:49,900
Um, who by show of hands, who has used an EEG before or played around with them or seen them.

436
00:49:50,270 --> 00:50:01,750
Yeah, yeah, yeah. That's great. Um, so our activity on Thursday, as I mentioned multiple times, will be actually using uh,

437
00:50:02,230 --> 00:50:09,890
these EEG or electroencephalogram to actually measure different states of relaxed.

438
00:50:09,910 --> 00:50:14,140
I think I'll bring in some speakers and headphones, and I encourage you to bring in your own.

439
00:50:14,590 --> 00:50:25,450
And we can kind of listen to different types of music and see how that can change our, uh, baseline, um, kind of relaxed or excited kind, of course.

440
00:50:25,840 --> 00:50:32,770
Uh, um, activity within the brain, uh, that can be measured through these EEGs.

441
00:50:33,310 --> 00:50:40,930
Right. And so these are, um, some form of extracellular recordings, except they're noninvasive, right?

442
00:50:40,960 --> 00:50:49,780
They're typically placed on our skin and they measure, um, changes in essentially local field potentials.

443
00:50:49,780 --> 00:50:56,350
So very similar to our electrodes, except, um, you're now integrating even more data across,

444
00:50:56,770 --> 00:51:02,350
um, an even wider, uh, uh, kind of field, uh, region of interest.

445
00:51:03,040 --> 00:51:11,169
Uh, and so you won't be able to, uh, resolve single spikes when we're using this, uh, but of course, what's great is that we actually can,

446
00:51:11,170 --> 00:51:18,460
you know, use these as a noninvasive way of measuring, you know, baseline or excited states, uh, within humans.

447
00:51:18,970 --> 00:51:25,870
Uh, as we'll see in class, uh, they're really commonly used to study different stages of sleep.

448
00:51:26,380 --> 00:51:34,150
And then on Thursday, we'll go into, um, you know, exactly what, uh, frequencies are picked up, uh,

449
00:51:34,150 --> 00:51:42,760
at different stages of sleep, going from, uh, non-REM, uh, one, two and three all the way to, uh, to rim sleep.

450
00:51:43,300 --> 00:51:50,560
Uh, folks, if folks want to actually take them home and try and measure different stages of sleep.

451
00:51:51,010 --> 00:51:54,490
Uh, we'll have three folks that will be able to do that if they want.

452
00:51:55,060 --> 00:52:01,330
Um, yeah. And then we'll kind of collect that data and start processing it even on Thursday.

453
00:52:03,010 --> 00:52:06,459
Right. And so that's kind of what I had for today.

454
00:52:06,460 --> 00:52:15,910
And we're going to get into more of the nitty gritty and um, yeah, the actual data for these EEG is on Thursday.

455
00:52:16,600 --> 00:52:21,170
Um, but yeah, I think we'll probably end a little bit early, but.

